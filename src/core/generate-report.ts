import 'dotenv/config';
import { TestReporter } from './test-reporter';
import { AIAnalyzer } from './ai-analyzer';
import { TestRunner } from './test-runner';
import { TestResult, TestAnalysis } from './types';
import * as path from 'path';
import * as fs from 'fs';

function validateEnvironment() {
  if (!process.env.HUGGINGFACE_API_TOKEN) {
    throw new Error('HUGGINGFACE_API_TOKEN environment variable is required');
  }
  if (!process.env.SITE_URL) {
    throw new Error('SITE_URL environment variable is required');
  }
}

async function cleanup(site: string) {
  // Clean up temporary directories
  const cleanupDirs = [
    'test-results',    // Playwright temp results
    'playwright-report' // Playwright temp report
  ];

  // Clean up generated test files
  const testFile = path.join('tests', 'sites', site, 'generated-performance.spec.ts');

  // Clean directories
  for (const dir of cleanupDirs) {
    if (fs.existsSync(dir)) {
      fs.rmSync(dir, { recursive: true, force: true });
      console.log(`Cleaned directory: ${dir}`);
    }
  }

  // Clean files
  if (fs.existsSync(testFile)) {
    fs.unlinkSync(testFile);
    console.log(`Cleaned file: ${testFile}`);
  }
}

async function waitForModelAvailability(analyzer: AIAnalyzer, maxAttempts = 5): Promise<void> {
  for (let attempt = 1; attempt <= maxAttempts; attempt++) {
    try {
      await analyzer.checkModelAvailability();
      return;
    } catch (error) {
      if (error instanceof Error && error.message.includes('currently loading')) {
        const waitTime = Math.min(attempt * 10, 30); // Exponential backoff, max 30 seconds
        console.log(`\nâ³ AI model is still loading. Waiting ${waitTime} seconds before retry (attempt ${attempt}/${maxAttempts})...`);
        await new Promise(resolve => setTimeout(resolve, waitTime * 1000));
      } else {
        throw error;
      }
    }
  }
  throw new Error('AI model failed to load after maximum retry attempts');
}

async function generateReport(site: string) {
  console.log('\nðŸ” Environment check:');
  validateEnvironment();

  const siteUrl = process.env.SITE_URL;
  if (!siteUrl) {
    throw new Error('SITE_URL environment variable is required');
  }

  console.log('\nðŸ§¹ Cleaning up temporary files...');
  await cleanup(site);

  console.log(`\nðŸ¤– Generating test cases for ${site}...`);
  const analyzer = new AIAnalyzer(process.env.HUGGINGFACE_API_TOKEN!);
  const testCases = await analyzer.generateTestCases(siteUrl);
  
  console.log(`\nâœ¨ Generated ${testCases.length} test cases`);
  testCases.forEach(test => console.log(`   â€¢ ${test.title}`));

  console.log('\nðŸ“ Generating test code...');
  const testCode = await analyzer.generateTestCode(testCases);
  const testFilePath = path.join(process.cwd(), 'tests', 'sites', site, 'generated-performance.spec.ts');
  await fs.promises.writeFile(testFilePath, testCode);
  console.log(`   ðŸ’¾ Test code saved to: ${testFilePath}`);

  console.log('\nðŸš€ Running generated tests...');
  const runner = new TestRunner(siteUrl);
  const results = await runner.runAllTests(testCases);

  // Verifica se hÃ¡ resultados
  if (!results || results.length === 0) {
    console.error('\nâŒ No test results generated.');
    process.exit(1);
  }

  // AnÃ¡lise dos resultados dos testes
  const passedTests = results.filter(r => r.status === 'passed');
  const failedTests = results.filter(r => r.status === 'failed');
  const criticalFailures = failedTests.filter(result => 
    result.error?.toLowerCase().includes('timeout')
  );

  // Log detalhado dos resultados
  console.log('\nðŸ“Š Test Results Analysis:');
  console.log(`   âœ… Passed Tests: ${passedTests.length}`);
  console.log(`   âŒ Failed Tests: ${failedTests.length}`);
  if (criticalFailures.length > 0) {
    console.log(`   âš ï¸  Critical Failures: ${criticalFailures.length}`);
  }

  // Verifica condiÃ§Ãµes para prosseguir
  if (failedTests.length === results.length) {
    console.error('\nâŒ All tests failed. Not generating reports.');
    console.error('Please check your network connection and try again.');
    process.exit(1);
  }

  if (criticalFailures.length > testCases.length / 2) {
    console.error('\nâŒ Too many critical failures detected. Not generating reports.');
    console.error('Failed tests:');
    criticalFailures.forEach(failure => {
      console.error(`   â€¢ ${failure.title}: ${failure.error}`);
    });
    process.exit(1);
  }

  // Gera relatÃ³rios usando o TestReporter
  console.log('\nðŸ’¾ Saving results...');
  const reporter = new TestReporter(site);
  results.forEach(result => reporter.addResult(result));
  reporter.generateReports();

  // SÃ³ prossegue com anÃ¡lise AI se houver testes bem-sucedidos
  if (passedTests.length > 0) {
    console.log('\nðŸ§  Analyzing test results...');
    try {
      // Aguarda disponibilidade do modelo antes de prosseguir
      await waitForModelAvailability(analyzer);
      const analysis = await analyzer.analyzeTestResults(results);
      console.log('   âœ… Analysis completed successfully');
    } catch (error) {
      console.error('\nâš ï¸  AI Analysis failed:', error instanceof Error ? error.message : 'Unknown error');
      console.log('   ðŸ“ Proceeding with basic report generation...');
    }
  }

  console.log('\nâœ¨ Reports generated successfully!');
  console.log(`   ðŸ’» You can now run "npm run ui:serve" to view the results for ${site}.`);
}

// Execute report generation
const site = process.argv[2];
if (!site) {
  console.error('Please provide a site name as an argument');
  process.exit(1);
}

generateReport(site).catch(error => {
  console.error('Error generating report:', error);
  process.exit(1);
}); 